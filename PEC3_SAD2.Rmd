---
title: "PEC3_SAD"
output: word_document
date: "21/5/2020"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/R/PEC3_SAD")
library(readr)
library(tidyr)
library(car)
library(lmtest)
library(foreign)
library(psych)
datosdf<- read.csv("sage_tae_2019_df.csv", skipNul = T)
View(datosdf)
```
# Estructura de los datos:

```{r}
str(datosdf)
```

# Valores NA.

```{r}
table(is.na(datosdf$AGE))
datosdf2 =na.omit(datosdf)
table(is.na(datosdf2))
```

# 1.5. PROBABILIDAD

## Distribución normal.

Tomamos como variable aleatoria la concentración de azúcar en sangre en ayunas, para dos grupos: enfermos o sanos. Suponemos que estos valores siguen una distribución normal en ambos grupos:
SANOS: N(4.7, 0.57)
DM2: N(11.4,3.9)

```{r}
FBSH<- subset(datosdf2$FBS..mmol.l., datosdf2$DM_status=="Healthy")
FBSDM <- subset(datosdf2$FBS..mmol.l., datosdf2$DM_status=="NDM")
mean(FBSH); sd(FBSH); mean(FBSDM); sd(FBSDM)
library(ggplot2)
ggplot(data.frame(x = c(1, 22)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 4.7, sd = 0.57), col='green') +
  stat_function(fun = dnorm, args = list(mean =4.7, sd =.57), xlim = c(6,7),
                geom = "area", fill = "green")+
  stat_function(fun = dnorm, args = list(mean = 11.4, sd = 3.9), col='red') +
  stat_function(fun = dnorm, args = list(mean= 11.4, sd =3.9), xlim = c(0,6),
                geom = "area", fill = "red")
```


### Se considera que los individuos con  valores de azúcar en sangre por encima de 7 serían clasificados como DM2.
¿qué porcentaje de la población se consideraría incorrectamente sana?
```{r}
library(fastGraph)
P1<- pnorm(7,mean=11.4,sd=3.9, lower.tail = T)
cat("la probabilidad de ser clasificado incorrectamente sano es:", P1)
```
```{r}
shadeDist(7,"dnorm",11.4, 3.9,lower.tail = T, col=c("red", "blue"), xlab="glc en ayunas(mmol/L)")
```

### ¿qué porcentaje se clasificaría como enfermo pero está realmente sano?
```{r}
P2<- pnorm(7, mean=4.7, sd=0.57, lower.tail = F)
cat("la probabilidad de ser clasificado erróneamente como DM2 es:", P2)
```
```{r}
shadeDist(7, "dnorm", 4.7, 0.57, lower.tail = F, col=c("red","blue"), xlab="glc en ayunas (mmol/L)")
```

### ¿Cuál es la probabilidad en el grupo de individuos con DM2 que se obtengan concentraciones entre 10 y 13?

```{r}
pnorm(c(13,10), mean = 11.4, sd=3.9)
cat("la probabilidad de obtener concentraciones entre 10 y 13 en DM2 es: ", 0.6592-0.3598)
```

### Determinar la concentración mínima del 30% de los individuos sanos con más concentración.

Equivale a calcular el quantil 25:
```{r}
qnorm(0.3, mean=4.7, sd=0.57)
```
es decir, P[X < 4.4] = 0.30

## Binomial.

### Si la probabilidad de tener DM2 es de un 8%, ¿que probabilidad hay de que si vienen 16 voluntarios a hacerse la analítica sean todos diabéticos?
Se trataria entonces de una distribución binomial: n = 16 y p = 0.08. (X  → B (16, 0.08))
```{r}
td<- dbinom(16,16,0.08)
cat("P[X=16]=",td)
```
Es prácticamente 0.

### ¿y de que más de la mitad lo sean?
```{r}
md<- pbinom(8,16,0.08)
cat("P[Sean diabéticos tipo 2 más de la mitad] = P[X > 8] = 1 – P[X =< 8] = 1 – F(8)=", 1-md)
```
También es muy poco probable.

### Y que ninguno sea diabético tipo 2?
```{r}
nd<- dbinom(0,16,0.08)
cat("P[ninguno sea diabético 2] = P[X = 0]=", nd)
```

### ¿Y la probabilidad de que, al menos, 2 sean diabéticos tipo2?
```{r}
dd<- 1-pbinom(1,16,0.08)
cat("P[por lo menos dos sean diabéticos] = P[X >= 2] = 1 – P[X < 2] = 1 – F(1)=", dd)
```

## Generar una muestra de tamaño 40 de la población con DM2. 

### Estimar la media de la muestra con su intervalo de confianza al 95%.
```{r}
set.seed(2027)
muestra<- rnorm(400, mean=4.7, sd=0.57)
media40<- mean(muestra)
sd40<- sd(muestra)
se40<- sd40/sqrt(length(muestra))
li40<- media40-qt(.975, length(muestra)-1)*se40
ls40<- media40+qt(.975, length(muestra)-1)*se40
cat("el intervalo de confianza es:",li40, ls40)
```
También se puede calcular con un t-test:
```{r}
t.test(muestra, conf.level = 0.95)
```
```{r}
hist(muestra,ylim=c(0,0.8), freq = F)
lines(density(muestra), col="red")
```

# 1.6. REGRESIÓN LINEAL

## Resumen estadístico:

```{r}
summary(datosdf2)
```

## Variables:
Parámetros de adiposidad: BMI, WC(perímetro cintura), Leptina(ng/ml), Adiponectina (µg/ml).
Parámetros metabólicos: FBS(mg/dl, azúcar en sangre en ayunas), TC (colesterol total, mg/dl), TG(triglicéridos, mg/dl), SBP y DBP(presión arterial sistólica y diastólica en mmHg), F.Ins.pmol.L.(µU / ml, insulina en sangre en ayunas), HOMA-IR (evaluación de modelo homeostático de resistencia a la insulina), HOMA-B(modelo homeostático de evaluación de la función de las células β); y la condición de tener DM2(diabetes mellitus tipo 2).

HOMA IR= (insul.en sangre en ayuno x glucosa en sangre en ayuno)/22.5

HOMA B= 20X insul. en sangre en ayuno x /(gluc. en ayuno-3.5)

Los no obesos son individuos con IMC <25(La OMS define a un adulto que tenga un BMI entre 25 y 29,9 como exceso de peso - adulto que tenga un BMI de 30 o más alto se considera obeso - un BMI abajo de 18,5 se considere peso insuficiente, y entre 18,5 a 24,9 al peso sano). 

### Normalidad de las variables:
```{r}
multi.hist(x = datosdf2[,c(2,4,5,6,7,8,12,13,14,15,16,17,18,20,21,22,23)], dcol = c("blue","red"), dlty = c("dotted", "solid"),
           main = "")
```
```{r}
library(foreign)
library(MVN)
mvn(data=datosdf2[,c(2,4,5,6,7,8,12,13,14,15,16,17,18,20,21,22,23)], mvnTest="royston", univariatePlot="box")
# Con esta función obtenemos la información estadística básica y un Test Shapiro-Wilk de normalidad de cada una de las variables.
```

### Correlación entre las variables.

```{r}
pairs(datosdf2[,c(4,5,6,11,12,22,23)], col=datosdf2$DM_status)
```
```{r}
library(corrplot)
library(RColorBrewer)
cordatos<- cor(datosdf2[,-c(1,3,6,9,10,11,18,19)])
corrplot(cordatos,type="upper", col = brewer.pal(n = 8, name = "RdYlBu"))
```

Observamos casos en los que la correlación es alta y por lo tanto aportan información redundante. Se excluirán algunos de estos predictores redundantes en el modelo: HOMA2B, HOMA2S, HOMA2.IR, Ins, FBS.

## Modelo lineal simple.

Como se puede ver en el gráfico anterior (scatterplot), parece que existe una relación lineal entre el IMC y el perímetro de la cintura(WC):
```{r}
MLS<-lm(data = datosdf2, formula =BMI~WC)
plot(x =datosdf2$BMI, y = datosdf2$WC, main = "WC VS IMC", pch = 20, col = "grey30")
```
```{r}
summary(MLS)
```
es decir, según el modelo, si mi cintura mide 65 cm, mi IMC sería:
```{r}
0.29*65-1.06
```

### Test de Pearson.
```{r}
cor.test(datosdf2$BMI, datosdf2$WC, method="pearson")
```
La correlación es alta.

### Normalidad de los errores:
```{r}
res<- rstandard(MLS)
par(mfrow=c(1,3))
hist(res)
boxplot(res)
qqnorm(res, pch=19,col = "gray50")
qqline(res)
```

### Varianza de los errores(heterocedasticidad):
```{r}
plot(fitted.values(MLS), rstandard(MLS), xlab="valores ajustados", ylab="residuos estandarizados")
abline(h=0, col="red")
```

### Valores atípicos:
```{r}
plot(datosdf2$WC, rstandard(MLS),xlab = "perímetro cintura", ylab="residuos estandarizados")
abline(h=0, col="red")
```
Los residuos parecen normales y la varianza es bastante constante. Hay algunos valores que presentan mucha dispersión.



## Modelo lineal múltiple.

Primero planteamos el modelo completo, con la resistencia a la insulina como variable predictora:
```{r}
LMC<- lm(HOMA_IR~ BMI + WC + TG+ TC+ FBS..mmol.l.+SBP+DBP+ F.Ins.pmol.L.+HOMA_B+ Adiponectin.microgm.ml...5000.X. +Leptin..ng.ml.+ Body.Fat....from.Age..BMI +DM_status,data = datosdf2)
summary(LMC)
```
Por los valores de R-squared, vemos que modelo se ajusta bastante bien. 

# 1.7. Anova.

Utilizamos las variables más significativas para crear un nuevo modelo simplificado:
```{r}
LMC2<- lm(HOMA_IR~ FBS..mmol.l.+ F.Ins.pmol.L.+HOMA_B+ DM_status,data = datosdf2)
summary(LMC2)
anova(LMC, LMC2)
```

Por los resultados obtenidos en Anova y los valores de R-squared, nos quedamos con este segundo modelo simplificado. 
```{r}

pairs(datosdf2[,c(6,11,12,22,23)], col=datosdf2$DM_status)
```

### Intervalos de confianza para los coeficientes:
```{r}
confint(LMC2)
```

### Diagnosis: normalidad, heterocedasticidad.

```{r}
plot(LMC2)

```
Los gráficos primero y tercero se utilizan para contrastar gráficamente la independencia, la homocedasticidad y la linealidad de los residuos. Idealmente, los residuos deben estar aleatoriamente distribuidos a lo largo del gráfico, sin formar ningún tipo de patrón.

El gráfico Q- Q, por su parte, se utiliza para contrastar la normalidad de los residuos. Lo deseable es que los residuos estandarizados estén lo más cerca posible a la línea punteada que aparece en el gráfico.

El gráfico de  leverages frente a los residuos estandarizados se utiliza para detectar puntos con una influencia importante en el cálculo de las estimaciones de los parámetros. En caso de detectarse algún punto fuera de los límites que establecen las líneas discontinuas debe estudiarse este punto de forma aislada para detectar, por ejemplo, si la elevada importancia de esa observación se debe a un error.

### Test de normalidad: Shapiro Wilk
```{r}
shapiro.test(residuals(LMC2))
```
Por el valor de p, rechazamos la hipótesis de normalidad de los residuos
También podemo realizar el test de Kolmogorov-Smirnov:
```{r}
ks.test(LMC2$residuals, "pnorm")
```
Los resultados del test nos confirman lo que se intuía en el gráfico Q-Q: a un 5% de significación los residuos no siguen una distribución normal, puesto que el p-valor que se obtiene es menor que 0.05.

### Heterocedasticidad: Varianza no constante de los residuos.

Test de puntuación de varianza no constante, y test de Breusch-Pagan:
```{r}
ncvTest(LMC2)
bptest(LMC2)
```

### Test de Durbin Watson:
```{r}
library(lmtest)
dwtest(LMC2)
```

De nuevo, rechazamos la hipótesis de que los residuos son independientes.

Otra manera de  comprobarlo:  ajustando una recta a los valores absolutos de los residuos (o sus raíces cuadradas) y los valores predichos:

```{r}
plot(fitted(LMC2),abs(residuals(LMC2)),xlab="Predict values",ylab="|Residuals|")
summary(lm(sqrt(abs(residuals(LMC2)))~fitted(LMC2)))
```
### Análisis gráfico autocorrelación de residuos:

```{r}
library(ggplot2)
ggplot(data = datosdf2, aes(x = seq_along(LMC2$residuals), 
                         y = LMC2$residuals)) +
geom_point(aes(color = LMC2$residuals)) +
scale_color_gradient2(low = "blue3", mid = "grey", high = "red") +
geom_line(size = 0.3) + 
labs(title = "Distribución de los residuos", x = "index", y = "residuo")+ 
geom_hline(yintercept = 0) + 
theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

### Leverage:

```{r}
plot(hatvalues(LMC2), type="h")
p<- length(LMC2$coefficients)
n<- length(LMC2$fitted.values)
cutoff<- 2*p/n
abline(h=cutoff, col="red")
```

```{r}
which(hatvalues(LMC2)>cutoff)
head(sort(hatvalues(LMC2), decreasing = T))
```
Los valores 38, 40, 41, 113, 43, y 91 son los que tienen un leverage más alto.

### Influencia:
```{r}
head(sort(cooks.distance(LMC2), decreasing = T))
```

Los valores 38,43 y 40 son los que tienen mayor influencia.

```{r}
summary(influence.measures(model=LMC2))
```
```{r}
influencePlot(model=LMC2)
```

Algunas observaciones tienen un residuo estandarizado absoluto próximo a 3 (1.73 si se considera la raíz cuadrada) lo que es indicativo de observación atípica. Valores de Leverages (hat) mayores que 2x((p+1)/n), siendo p el número de predictores y n el número de observaciones, o valores de Cook mayores de 1 se consideran influyentes. 
Todo ello reduce en gran medida la robustez de la estimación del error estándar de los coeficientes de correlación estimados y con ello la del modelo es su conjunto.

## Hipótesis de 2 modelos:

¿Depende la resistencia a la insulina de ser obeso? y de ser diabético tipo 2?


Uilizaremos HOMA_IR como predictor, para ver si existen diferencias en función de ser o no diabético, y de ser obeso o no.

```{r}
par(mfrow=c(1,2))
boxplot(HOMA_IR~ DM_status, data=datosdf2, col=c(3,2))
boxplot(HOMA_IR~BMI_group, data = datosdf2, col=c(3,2))
```
```{r}
ggplot(data = datosdf2) +
  geom_boxplot(aes(x = DM_status, y = HOMA_IR, colour = DM_status)) +
  theme_bw() + theme(legend.position = "none")
ggplot(data = datosdf2) +
  geom_boxplot(aes(x = BMI_group, y = HOMA_IR, colour = BMI_group)) +
  theme_bw() + theme(legend.position = "none")


```

### Test de Fisher.
Para saber si existe relación entre dos variables categóricas, podemos hacer un test de Fisher a partir de una tabla de contingencia:
```{r}
tabla <- table(datosdf2$BMI_group, datosdf2$DM_status, dnn = c("obeso o no", "diabético o no"))
ggplot(data = datosdf2) +
  geom_count(mapping = aes(x = BMI_group, y = DM_status))

```
Ho : Las variables son independientes por lo que una variable no varía entre los distintos niveles de la otra variable.
Ha: Las variables son dependientes, una variable varía entre los distintos niveles de la otra variable.

```{r}
fisher.test(x = tabla, alternative = "two.sided")
```
No podríamos rechazar la hipótesis nula (alpha=0.05).
Dado que el test de Fisher contrasta si las variables están relacionadas, al tamaño del efecto se le conoce como fuerza de asociación. Existen múltiples medidas de asociación, entre las que destacan phi o Cramer’s V. Los límites empleados para su clasificación son:
pequeño: 0.1
mediano: 0.3
grande: 0.5
En R se pueden calcular mediante la función assocstats() del paquete vcd.
```{r}
library(grid)
library(vcd)
assocstats(x = tabla)
```
En este ejemplo no se satisface la condición de frecuencias marginales fijas y por lo tanto el test de Fisher no es exacto. Aun así, parece ser que las dos variables no están relacionadas. El tamaño de la fuerza de asociación (tamaño de efecto) cuantificado por phi o Cramer’s V es grande.

### χ2 de Pearson (test de independencia)
Es el test aproximado equivalente a su versión exacta test de Fisher. Debido a los requerimientos de cálculo del test de Fisher, cuando hay muchas observaciones o muchos niveles, se emplea el test χ2 de independencia. 
La distribución chi-cuadrado es siempre positiva, por lo que para calcular el p-value solo se tiene en cuenta la cola superior.
```{r}
chisq.test(x = tabla)
```
Solución mediante simulación:
```{r}
chisq.test(tabla, simulate.p.value = TRUE, B = 5000)
```

# Anova. 

Contrastamos si la resistencia a la insulina es igual en diabético y no diabéticos, y en obesos o no:
```{r}
anova(lm(HOMA_IR~DM_status, data = datosdf2))
anova(lm(HOMA_IR~BMI_group, data = datosdf2))
```

Los valores de HOMA_IR dependen de la condición de estar o no enfermo, pero no del IMC (nivel de significación 0.05)

Se podría estudiar también como influyen las variables en la resistencia a la insulina, pero específicamente en individuos diabéticos y/o sanos independientemente, de esta manera obtenemos valores de t para cada grupo
```{r}
datHealth<- subset(datosdf2, datosdf2$DM_status=="Healthy")
datDM <- subset(datosdf2, datosdf2$DM_status=="NDM")
lmH<- lm(HOMA_IR~ BMI + WC + TG+ TC+ FBS..mmol.l.+SBP+DBP+ F.Ins.pmol.L.+HOMA_B+ Adiponectin.microgm.ml...5000.X. +Leptin..ng.ml.,data = datHealth)
lmDM<-lm(HOMA_IR~ BMI + WC + TG+ TC+ FBS..mmol.l.+SBP+DBP+ F.Ins.pmol.L.+HOMA_B+ Adiponectin.microgm.ml...5000.X. +Leptin..ng.ml., data = datDM)
summary(lmH);summary(lmDM)
```
Por los valores de R-squared, estos modelos explicarían un alto porcentaje de la variabilidad. Observamos que los niveles de leptina son más significativos en el caso de los individuos sanos, en cambio en el caso de los diabéticos es más significativa la adiponectina. Además, vemos que los niveles de azúcar en ayunas, aunque explican algo de variabilidad, no son tan significantes en el caso de los diabéticos, pero sí en el grupo de individuos sanos. 

Por lo tanto, estos modelos también se pueden simplificar usando las variables con nivel de significación más alto:
```{r}
lmH2<- lm(HOMA_IR~ FBS..mmol.l.+ F.Ins.pmol.L.+HOMA_B+ Leptin..ng.ml.,data = datHealth)
lmDM2<-lm(HOMA_IR~ F.Ins.pmol.L.+HOMA_B+ Adiponectin.microgm.ml...5000.X., data = datDM)
anova(lmH, lmH2)
anova(lmDM, lmDM2)
summary(lmH2); summary(lmDM2)
confint(lmH2); confint(lmDM2)
```
De nuevo, nos quedaríamos con el modelo más simple (en ambos grupos).
```{r}
plot(lmH2)
plot(lmDM2)
shapiro.test(residuals(lmH2))
shapiro.test(residuals(lmDM2))
ncvTest(lmH2)
ncvTest(lmDM2)
bptest(lmH2)
bptest(lmDM2)
```


De nuevo obtenemos resultados de no-normalidad y heterocedasticidad en los residuos.Podría ser útil plantearnos una transformación de los datos, o utilizar un test no parmétrico, como el test de Kruskal-Wallis.

## Representación del plano de regresión.
Por último, dado un modelo con dos predictores continuos,se puede representar el plano de regresión. Como ejemplo utilizaremos la glucemia e insulinemia como predictores de la IR:
```{r}
modelo<- lm(HOMA_IR~FBS+Ins, data = datosdf2)
rango_fbs <- range(datosdf2$FBS)
nuevos_valores_fbs <- seq(from = rango_fbs[1], to = rango_fbs[2],
                            length.out = 200)
rango_ins <- range(datosdf2$Ins)
nuevos_valores_ins <- seq(from = rango_ins[1], to = rango_ins[2],
                          length.out = 200)

predicciones <- outer(X = nuevos_valores_fbs, Y = nuevos_valores_ins, 
                      FUN = function(FBS,Ins) {
                          predict(object = modelo,
                                  newdata = data.frame(FBS,Ins))
                          })

superficie <- persp(x = nuevos_valores_fbs, y = nuevos_valores_ins,
                    z = predicciones,
                    theta = 40, phi = 10,
                    col = "lightblue", shade = 0.1,
                    zlim = range(-40,300),
                    xlab = "FBS", ylab = "INS", zlab = "IR",
                    ticktype = "detailed",
                    main = "IR media ~ FBS Y INS"
                  )

observaciones <- trans3d(datosdf2$FBS, datosdf2$Ins, datosdf2$HOMA_IR, superficie)
error <- trans3d(datosdf2$FBS, datosdf2$Ins, fitted(modelo), superficie)
points(observaciones, col = "red", pch = 16)
segments(observaciones$x, observaciones$y, error$x, error$y)
```


# 1.8. Conclusiones.

1. El IMC sigue una relación lineal positiva con el perímetro de la cintura.
2. El IMC no parece influir directamente en ser resistente a la insulina. Hemos visto que no hay diferencias significativas entre los grupos obeso/no obeso en general, pero podríamos analizar también si existen diferencias entre obesos y no dentro de cada grupo DM2 no-DM2. En cambio sí que la resistencia a la insulina difiere entre diabéticos o no diabéticos.
3. Los parámetros que más influyen en ser resistente son: para ambos grupos, niveles de insulina en sangre en ayunas y la función de las células beta (de manera negativa, como era de esperar). Observamos que los niveles de leptina son más significativos en el caso de los individuos sanos, en cambio en el caso de los diabéticos es más significativa la adiponectina, ambos de manera negativa también. Los niveles de azúcar en ayunas, aunque explican algo de variabilidad, no son tan significativos en el caso de los diabéticos, pero sí en el grupo de individuos sanos.
4. Sería necesario estudiar otras variables como podrían ser algunos factores externos: la ingesta de glucosa diaria, el índice glucémico o insulínico de los alimentos en la dieta, tipo de  actividad física realizada. Así como parámetros metabólicos, por ejemplo la hemoglobina glicosilada (HbA1c), un parámetro que mide el grado de glicosidación que sufre la molécula de hemoglobina durante la vida del hematíe (unos 180 días) y que por tanto, constituye un promedio de la concentración de glucosa en sangre que el individuo ha mantenido durante ese tiempo, reflejando mejor la glucemia que la medida puntual de una concentración de glucose en ayunas.

Otras cuestiones que nos podríamos haber planteado son:

1. ¿Existe relación entre los niveles de insulina en plasma y alguno de los parámetros de adiposidad?
2. Como hemos mencionado, sería necesario dividir la muestra entre grupos obesos-no obesos y analizar de nuevo las diferencias entre diabéticos o no diabéticos de algunos de los parámetros metabólicos(insulina, IR, leptina,...).




